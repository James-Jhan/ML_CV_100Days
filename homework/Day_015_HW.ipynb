{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train, std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "C:\\Users\\James\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 25s 507us/step - loss: 1.5224 - acc: 0.4699\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.0651 - acc: 0.6245\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.9318 - acc: 0.6740\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.8667 - acc: 0.6966\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.8141 - acc: 0.7182\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.7592 - acc: 0.7350\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.7235 - acc: 0.7479\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.6829 - acc: 0.7604\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.6528 - acc: 0.7718\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.6223 - acc: 0.7816\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.5802 - acc: 0.7971\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.5559 - acc: 0.8062\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.5244 - acc: 0.8153\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.5042 - acc: 0.8226\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.4789 - acc: 0.8329\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.4456 - acc: 0.8439\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 0.4253 - acc: 0.8494\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 14s 276us/step - loss: 0.4051 - acc: 0.8574\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.3815 - acc: 0.8657\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.3623 - acc: 0.8724\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.3489 - acc: 0.8769\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.3312 - acc: 0.8833\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.3184 - acc: 0.8878\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.2966 - acc: 0.8946\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.2829 - acc: 0.8986\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.2606 - acc: 0.9078\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.2524 - acc: 0.9098\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.2434 - acc: 0.9126\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.2387 - acc: 0.9151\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.2128 - acc: 0.9246\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 0.2118 - acc: 0.9261\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 0.1992 - acc: 0.9282\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.1838 - acc: 0.9341\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.1838 - acc: 0.9343\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.1697 - acc: 0.9396\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.1612 - acc: 0.9428\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.1562 - acc: 0.9449\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 0.1500 - acc: 0.9462\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.1428 - acc: 0.9492\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 0.1467 - acc: 0.9469\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.1439 - acc: 0.9491\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.1186 - acc: 0.9582\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.1193 - acc: 0.9567\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 0.1277 - acc: 0.9541\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 0.1182 - acc: 0.9575\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 0.1090 - acc: 0.9615\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 0.1106 - acc: 0.9605\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 0.1063 - acc: 0.9621\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.1055 - acc: 0.9620\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0996 - acc: 0.9638\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.0890 - acc: 0.9679\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.0965 - acc: 0.9659\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0893 - acc: 0.9687\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 0.0913 - acc: 0.9678\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0975 - acc: 0.9649\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0803 - acc: 0.9719\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 0.0750 - acc: 0.9738\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.0781 - acc: 0.9732\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.0886 - acc: 0.9689\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0821 - acc: 0.9710\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0694 - acc: 0.9762\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0782 - acc: 0.9725\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.0723 - acc: 0.9750\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.0759 - acc: 0.9730\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 0.0731 - acc: 0.9745\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0768 - acc: 0.9729\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 0.0588 - acc: 0.9794\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.0788 - acc: 0.9713\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0605 - acc: 0.97950s - loss: 0.06\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0607 - acc: 0.9792\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 0.0645 - acc: 0.9777\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0671 - acc: 0.9764\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 0.0514 - acc: 0.9828\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0630 - acc: 0.9776\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0600 - acc: 0.9792\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0537 - acc: 0.9815\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 0.0681 - acc: 0.9760\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0642 - acc: 0.9771\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0568 - acc: 0.9799\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0557 - acc: 0.9810\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 0.0523 - acc: 0.9818\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0523 - acc: 0.9814\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0577 - acc: 0.9796\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0575 - acc: 0.9795\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.0467 - acc: 0.9833\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0594 - acc: 0.9787\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0582 - acc: 0.9805\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0512 - acc: 0.9821\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0491 - acc: 0.9832\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0540 - acc: 0.9809\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 0.0462 - acc: 0.9842\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0447 - acc: 0.9852\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.0492 - acc: 0.9834\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 0.0459 - acc: 0.9845\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 0.0532 - acc: 0.9819\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 0.0420 - acc: 0.9855\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 0.0516 - acc: 0.9821\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 14s 284us/step - loss: 0.0541 - acc: 0.9813\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.0472 - acc: 0.9827\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 0.0464 - acc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8d5293438>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "from keras.layers import Activation\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3)))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "#自己決定MaxPooling2D放在哪裡\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, kernel_size=(3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(activation='relu', output_dim=100)) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3075610e-01, 1.0882712e-02, 1.9028737e-01, 4.3743828e-01,\n",
       "        2.5388407e-02, 2.6034916e-04, 2.4753698e-04, 9.5525742e-08,\n",
       "        4.7392175e-03, 1.2930308e-08]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
